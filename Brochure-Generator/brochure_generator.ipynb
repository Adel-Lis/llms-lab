{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78af87ef",
   "metadata": {},
   "source": [
    "# Markdown Brochure Generator\n",
    "\n",
    "In this small exercise I use [Gradio](https://www.gradio.app/) in order to implement a simple Markdown brochure generator for an website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d69cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "736e58a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyCN\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52de3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "gemini = genai.Client(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b4efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are an assistant that analyzes the contents of a website landing page and creates a short brochure about the company for prospective customers, investors and recruits. Include details of company culture, customers and careers/jobs if you have the information. Respond in Markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232980c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_stream_answer(prompt, system_message):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe4fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_stream_answer(prompt, system_message):\n",
    "    result = claude.messages.stream(\n",
    "        model=\"claude-3-5-haiku-latest\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        system=system_message,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            response += text or \"\"\n",
    "            yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15513cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_stream_answer(prompt, system_message):\n",
    "    stream = gemini.models.generate_content_stream(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt,\n",
    "        config=types.GenerateContentConfig(system_instruction=system_message, temperature=0.7)\n",
    "    )\n",
    "\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.text or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "062e0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f94ea7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_system_prompt(preference = \"\", system_initial = SYSTEM_PROMPT):\n",
    "    if preference == \"Professional\":\n",
    "        system_initial += \"\\nYour answer is very professional and corporate oriented. You answer is paragraphs and bulletpoints that describe clearly the company. You DO NOT use emojies, slangs or any other unprofessional language. You emphasise the history of the company and the product (or main thing) that they are representing. You report links and other references. Your tone is simple and professional, like the CEO of the company.\"\n",
    "    elif preference == \"Funny\":\n",
    "        system_initial += \"\\nYour answer is hunny and friendly at the same time. You use emojies to capture the attention and cute, friendly, short words that seems to explain things faster. You answer is small text and bulletpoints. Your answer is like you talking or promoting the company to a friend in a friendly and gentle way.\"\n",
    "    elif preference == \"Statistical\":\n",
    "        system_initial += \"\\nYour answer is mainly focust on statistical data. You role is to better represent data and numbers in the best way. You tone is simple, neutral and result-oriented. You do not focus on the history or employee, instead you use the company and its role to better explain and represent the company's data. You do not use emojies and you answer mostly in paragraphs.\"\n",
    "    elif preference == \"Sarcastic\":\n",
    "        system_initial += \"\\nYour answer is sarcastic and contains a lot of small jokes and double-meaning about the company. You do not want to offend them, but the brochure you are creating is roasting them a bit. You maintain the respect about the company and your only goal of the brochure is to talk about the company and make people smaile and laugh a bit. You can use silly and funny emojie around the texts and you answer is mixed between paragraphs, some lists and maybe punhlines.\"\n",
    "\n",
    "    return system_initial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488f8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model, tone):\n",
    "    system_message = customized_system_prompt(tone, SYSTEM_PROMPT)\n",
    "\n",
    "    yield \"\"\n",
    "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += Website(url).get_contents()\n",
    "    if model == \"GPT\":\n",
    "        result = gpt_stream_answer(prompt, system_message)\n",
    "    elif model == \"Claude\":\n",
    "        result = claude_stream_answer(prompt, system_message)\n",
    "    elif model == \"Gemini\":\n",
    "        result = gemini_stream_answer(prompt, system_message)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name : \"),\n",
    "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
    "        gr.Dropdown([\"GPT\", \"Claude\", \"Gemini\"], label=\"Select Model\", value=\"GPT\"),\n",
    "        gr.Dropdown([\"Professional\", \"Funny\", \"Statistical\", \"Sarcastic\"], label=\"Select the tone of the brochure :\", value=\"Professional\")\n",
    "    ],\n",
    "    outputs=[gr.Markdown(label=\"Brochure :\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad773ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "view.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
